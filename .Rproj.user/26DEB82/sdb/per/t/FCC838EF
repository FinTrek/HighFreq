{
    "contents" : "################################################\n###\n###  parsing and aggregating HFREQ data\n###\n################################################\n\nrm(list=ls())  # remove all objects\n\nlibrary(utils)\nlibrary(quantmod)\nlibrary(qmao)\nlibrary(caTools)\nlibrary(lubridate)\nlibrary(highfrequency)\nlibrary(quantstrat)\nlibrary(HighFreq)\n\nSys.setenv(TZ=\"America/New_York\")  # Set the time-zone to GMT\nsetwd(\"C:/Develop/data\")\n# search()  # get search path\noptions(digits.secs=6)\noptions(digits=5)\noptions(stringsAsFactors=FALSE)\noptions(max.print=80)\n\n\n### set data_dir directory\n# data_dir <- \"/home/storage/settles/\"\n# data_dir <- \"/home/storage/sec/\"\ndata_dir <- \"E:/mktdata/sec/\"\nscrub_dir <- \"E:/scrubdata/\"\n# data_dir <- \"/home/storage/tick/\"\n# print(data_dir)\n\n\n\n###########\n# code for loading instruments data\n\nsym_bols <- read.csv(file=\"etf_list_hf.csv\")\nsym_bols <- sym_bols[[1]]\n\n### load list of instrument definitions: creates .instrument environment\nloadInstruments(file_name='E:/mktdata/instruments.rda')\n\n# explore the .instrument environment\n# list instrument names in the .instrument environment (character vector)\n# ls_instruments()  # vary large list!!!\n# ls(FinancialInstrument:::.instrument)\n# ls_instruments() bigger than ls(FinancialInstrument:::.instrument)\nlist.instruments <- ls_instruments()\nlength(list.instruments)\nsample(list.instruments, 11)\ntail(list.instruments)\nwrite.csv(list.instruments, file=\"instruments.txt\")\n\n\n# get tickers for all stocks\n# ls_instruments_by('type', 'stock')  # very large list!!!\n# find.instrument(\"stock\")  # very large list!!!\n# get tickers for all computer stocks\nfind.instrument(\"computer\")\n# get tickers for all bond instruments\nfind.instrument(\"bond\")\n\n\n# get contract specs for instrument \"First Solar stock\"\ngetInstrument(\"FSLR\")\n# explore a few instrument objects\nan.instrument <- getInstrument(\"MSFT\")\nan.instrument <- getInstrument(\"BAXH3\")\nan.instrument$type\nan.instrument$series_description\n\n\n\n###########\n# extra code for parsing list.instruments - you can ignore\n\nconvert_NULL_NA <- function(in.var) {\n  if (is.null(in.var))\n    ret.var <- NA\n  else\n    ret.var <- in.var\n  ret.var\n}  # end convert_NULL_NA\n\nattr.instrument <- function(name.instrument) {\n  my.instrument <- getInstrument(name.instrument)\n  c(name=convert_NULL_NA(my.instrument$primary_id[1]), type=convert_NULL_NA(my.instrument$type[1]), longName=convert_NULL_NA(my.instrument$longName[1]), description=convert_NULL_NA(my.instrument$series_description[1]))\n}  # end attr.instrument\n\n# table.instruments <- apply(as.matrix(sample(list.instruments, 5)), 1, attr.instrument)\ntable.instruments <- aperm(sapply(sample(list.instruments, 11), attr.instrument), c(2,1))\ntable.instruments <- aperm(sapply(list.instruments, attr.instrument), c(2,1))\nwrite.csv(table.instruments, file=\"table.instruments.txt\")\nunique(table.instruments[, \"type\"])\nwrite.csv(unique(table.instruments[, \"longName\"]), file=\"unique.instruments.txt\")\n\n### end code for parsing list.instruments\n\n\n\n###########\n# load ts data using getSymbols.FI\n\n### set defaults for getSymbols\n# setDefaults(getSymbols, verbose=FALSE, dir=data_dir, src=\"rda\")\n\n# setDefaults for getSymbols: call getSymbols.FI by default\nsetDefaults(getSymbols, verbose=FALSE, src=\"FI\")\n# setDefaults for getSymbols.FI: load data from local drive\nsetDefaults(getSymbols.FI,\n            extension=\"RData\",\n            dir=data_dir,\n            days_to_omit=\"Saturday\",\n            use_identifier=\"X.RIC\")\n\n\n### load seconds bar data using getSymbols.FI\n\n# run loadInstruments() first\nsym_bol <- \"SPY\"\ngetSymbols(sym_bol)  # takes very long!!!\ndim(SPY)\nSPY[10000:10020, ]\n\n\n\n###########\n# load ts data using custom functions\n\n# create path to directory with *.RData files\nfile_dir <- file.path(data_dir, sym_bol)\n# get list of *.RData files\nfile_list <- list.files(file_dir)\n# create paths to *.RData files\nfile_names <- file.path(file_dir, file_list)\n\n# load data into list\ndaily_xts <- sapply(head(file_names), function(file_name) {\n  cat(\"loading\", file_name, \"\\n\")\n  data_name <- load(file_name)\n  get(data_name)\n})\nlength(daily_xts)\n\n# scrub and aggregate the data\ndaily_xts <- lapply(daily_xts, scrub_agg)\n\n# flatten list into xts - blows up or takes very long!!!\n# daily_xts <- do.call(rbind, daily_xts)\n# recursively \"rbind\" the list into a single xts\ndaily_xts <- do_call_rbind(daily_xts)\n\n\n# rename the colnames\ncolnames(daily_xts) <- sapply(strsplit(colnames(daily_xts), split=\"[.]\"), \n                                 function(strng) paste(sym_bol, strng[-1], sep=\".\"))\n\nhead(daily_xts)\nchartSeries(daily_xts, name=sym_bol, theme=chartTheme(\"white\"))\nchartSeries(daily_xts[\"2008-01-04/2008-01-06\"], name=sym_bol, theme=chartTheme(\"white\"))\n\n# install HighFreq\ninstall.packages(pkgs=\"C:/Develop/R/HighFreq\", repos=NULL, type=\"source\")\ninstall.packages(pkgs=\"C:/Develop/R/HighFreq\", repos=NULL, type=\"source\", lib=\"C:/Users/Jerzy/Downloads\")\ninstall.packages(pkgs=\"C:/Develop/R/HighFreq\", repos=NULL, type=\"source\", lib=\"C:/Users/Jerzy/Documents/R/win-library/3.1\")\nlibrary(HighFreq)\n\n# package library path\n.rs.rpc.get_package_install_context()\n.libPaths()\nnormalizePath(R.home())\nnormalizePath(R.home(\"Library\"))\nnormalizePath(.Library)\n\ninstall.packages(\"devtools\")\nlibrary(devtools)\ninstall_github(\"hadley/devtools\")\ninstall_github(repo=\"hadley/babynames\")\n\n\n###########\n# scrubbing functions\n\n\n### identify suspect bid_offer values in univariate xts time series\nsuspect_bid_offer <- function(bid_offer, agg_vol_window=51, suspect_threshold=2) {\n\n  stopifnot(\n    ((\"package:xts\" %in% search()) || require(\"xts\", quietly=TRUE))\n    &&\n      (\"package:caTools\" %in% search()) || require(\"caTools\", quietly=TRUE)\n  )\n\n# calculate vo_lat as running quantile\n  vo_lat <- runquantile(x=abs(as.vector(bid_offer)), k=agg_vol_window, probs=0.9, endrule=\"constant\", align=\"center\")\n  vo_lat <- xts(vo_lat, order.by=index(bid_offer))\n  colnames(vo_lat) <- \"volat\"\n# carry forward non-zero vo_lat values\n  vo_lat[vo_lat==0] <- NA\n  vo_lat[1] <- 1\n  vo_lat <- na.locf(vo_lat)\n#  vo_lat <- na.locf(vo_lat, fromLast=TRUE)\n  \n# find suspect values\n# suspect if bid_offer greater than vo_lat\n  sus_pect <- (abs(bid_offer) > 2*suspect_threshold*vo_lat)\n  sus_pect[1] <- FALSE\n\n  cat(\"date:\", format(as.Date(index(first(bid_offer)))), \"\\tscrubbed\", sum(sus_pect), \"suspect bid-offer values\\n\")\n  sus_pect\n}  # end suspect_bid_offer\n\n\n### identify suspect jump values in univariate xts price time series\nsuspect_jump <- function(price_data, agg_vol_window=51, suspect_threshold=2) {\n\n  stopifnot(\n    ((\"package:xts\" %in% search()) || require(\"xts\", quietly=TRUE))\n    &&\n      (\"package:caTools\" %in% search()) || require(\"caTools\", quietly=TRUE)\n  )\n\n# calculate simple returns\n  diff_prices <- diff(price_data)\n  diff_prices[1, ] <- 0\n  colnames(diff_prices) <- \"diffs\"\n  diff_prices_fut <- lag(diff_prices, -1)\n  diff_prices_fut[nrow(diff_prices_fut)] <- 0\n  colnames(diff_prices_fut) <- \"diff_prices_fut\"\n\n# calculate vo_lat as running quantile\n  vo_lat <- runquantile(x=abs(as.vector(diff_prices)), k=agg_vol_window, probs=0.9, endrule=\"constant\", align=\"center\")\n  vo_lat <- xts(vo_lat, order.by=index(diff_prices))\n  colnames(vo_lat) <- \"volat\"\n# carry forward non-zero vo_lat values\n  vo_lat[vo_lat==0] <- NA\n  vo_lat[1] <- 1\n  vo_lat <- na.locf(vo_lat)\n#  vo_lat <- na.locf(vo_lat, fromLast=TRUE)\n  \n# find suspect values\n# suspect if abs diffs greater than vo_lat, and if abs sum of diffs less than vo_lat\n  sus_pect <- (\n    (abs(diff_prices) > suspect_threshold*vo_lat) & \n      (abs(diff_prices_fut) > suspect_threshold*vo_lat) & \n      (abs(diff_prices+diff_prices_fut) < 2*suspect_threshold*vo_lat)\n  )\n  sus_pect[1] <- FALSE\n  colnames(sus_pect) <- \"suspect\"\n# cat(\"Parsing\", deparse(substitute(taq_data)), \"\\n\")\n# cat(\"Parsing\", strsplit(deparse(substitute(taq_data)), split=\"[.]\")[[1]][4], \"on date:\", format(to_day), \"\\tscrubbed\", sum(sus_pect), \"suspect values\\n\")\n  cat(\"date:\", format(as.Date(index(first(price_data)))), \"\\tscrubbed\", sum(sus_pect), \"suspect jump values\\n\")\n  sus_pect\n}  # end suspect_jump\n\n\n\n### scrub and aggregate a single day of TAQ data in xts format\n# return mid price and volume\nscrub_agg <- function(taq_data, agg_vol_window=51, suspect_threshold=2) {\n\n  stopifnot(\n      ((\"package:xts\" %in% search()) || require(\"xts\", quietly=TRUE))\n    &&\n      ((\"package:lubridate\" %in% search()) || require(\"lubridate\", quietly=TRUE))\n  )\n\n# convert time index to New_York\n  index(taq_data) <- with_tz(index(taq_data), \"America/New_York\")\n# subset data to NYSE trading hours\n  taq_data <- taq_data['T09:30:00/T16:00:00', ]\n# return NULL if no data\n  if (nrow(taq_data)==0)  return(NULL)\n  to_day <- as.Date(index(first(taq_data)))\n\n# remove duplicate time stamps using duplicated\n  taq_data <- taq_data[!duplicated(index(taq_data)), ]\n\n# scrub quotes with suspect bid-offer spreads\n  bid_offer <- taq_data[, 'Ask.Price'] - taq_data[, 'Bid.Price']\n#  bid_offer <- na.omit(bid_offer)\n  sus_pect <- suspect_bid_offer(bid_offer)\n# remove suspect values\n  taq_data <- taq_data[!sus_pect]\n# replace suspect values\n# taq_data[sus_pect, \"Bid.Price\"] <- taq_data[sus_pect, \"Trade.Price\"]\n# taq_data[sus_pect, \"Ask.Price\"] <- taq_data[sus_pect, \"Trade.Price\"]\n\n# scrub quotes with suspect price jumps\n# calculate mid prices\n  mid_prices <- 0.5 * (taq_data[, \"Bid.Price\"] + taq_data[, \"Ask.Price\"])\n#  mid_prices <- na.omit(mid_prices)\n  colnames(mid_prices) <- \"Mid.Price\"\n# replace suspect values with NA\n  mid_prices[suspect_jump(mid_prices)] <- NA\n  mid_prices <- na.locf(mid_prices)\n#  mid_prices <- na.locf(mid_prices, fromLast=TRUE)\n  mid_prices <- cbind(mid_prices, taq_data[index(mid_prices), \"Volume\"])\n  mid_prices[is.na(mid_prices[, \"Volume\"]), \"Volume\"] <- 0\n\n# aggregate to OHLC minutes data and cumulative volume\n  mid_prices <- to.period(x=mid_prices, period=\"minutes\")\n# round up times to next minute\n  index(mid_prices) <- align.time(x=index(mid_prices), 60)\n  mid_prices\n}  # end scrub_agg\n\n\n\n### scrub and return a single day of TAQ data\nscrub_TAQ <- function(taq_data, agg_vol_window=51, suspect_threshold=2) {\n\n  stopifnot(\n    ((\"package:xts\" %in% search()) || require(\"xts\", quietly=TRUE))\n    &&\n      ((\"package:lubridate\" %in% search()) || require(\"lubridate\", quietly=TRUE))\n  )\n\n# convert time index to New_York\n  index(taq_data) <- with_tz(index(taq_data), \"America/New_York\")\n# subset data to NYSE trading hours\n  taq_data <- taq_data['T09:30:00/T16:00:00', ]\n# return NULL if no data\n  if (nrow(taq_data)==0)  return(NULL)\n\n# remove duplicate time stamps using duplicated\n  taq_data <- taq_data[!duplicated(index(taq_data)), ]\n\n# scrub quotes with suspect bid-offer spreads\n  bid_offer <- taq_data[, 'Ask.Price'] - taq_data[, 'Bid.Price']\n#  bid_offer <- na.omit(bid_offer)\n  sus_pect <- suspect_bid_offer(bid_offer)\n# remove suspect values\n  taq_data <- taq_data[!sus_pect]\n# replace suspect values\n# taq_data[sus_pect, \"Bid.Price\"] <- taq_data[sus_pect, \"Trade.Price\"]\n# taq_data[sus_pect, \"Ask.Price\"] <- taq_data[sus_pect, \"Trade.Price\"]\n\n# scrub quotes with suspect price jumps\n# calculate mid prices\n  mid_prices <- 0.5 * (taq_data[, \"Bid.Price\"] + taq_data[, \"Ask.Price\"])\n#  mid_prices <- na.omit(mid_prices)\n  colnames(mid_prices) <- \"Mid.Price\"\n# replace suspect values with NA\n  mid_prices[suspect_jump(mid_prices)] <- NA\n  mid_prices <- na.locf(mid_prices)\n#  mid_prices <- na.locf(mid_prices, fromLast=TRUE)\n  mid_prices <- cbind(mid_prices, taq_data[index(mid_prices), \"Volume\"])\n  mid_prices[is.na(mid_prices[, \"Volume\"]), \"Volume\"] <- 0\n\n# aggregate to OHLC minutes data and cumulative volume\n  mid_prices <- to.period(x=mid_prices, period=\"minutes\")\n# round up times to next minute\n  index(mid_prices) <- align.time(x=index(mid_prices), 60)\n  mid_prices\n}  # end scrub_TAQ\n\n\ndaily_scrub <- scrub_agg(taq_data=daily_xts[[3]])\nchartSeries(daily_scrub, name=sym_bol, theme=chartTheme(\"white\"))\n\n# daily_xts <- NULL\n# sapply(head(file_names), function(file_name) {\n#   cat(\"loading\", file_name, \"\\n\")\n#   data_name <- load(file_name)\n#   daily_xts <<- rbind(daily_xts, get(data_name))\n#   data_name\n# })\n\n\n###########\n# subset ts data\n\n# subset time to trading hours using function from highfrequency - takes very long!!!\n# system.time(subset.SPY <- exchangeHoursOnly(SPY['2014-05-08/2014-05-16', ]))\n# subset time to trading hours\nsubset.SPY <- SPY['T09:30:00/T16:00:00', ]  # takes very long!!!\n# subset time to trading hours + 15 min pre/after market\nsubset.SPY <- SPY['T09:15:00/T16:15:00', ]  # takes very long!!!\nplot(subset.SPY['2014-05-12/2014-05-16', 'Bid.Price'])  # takes very long!!!\n# chart_Series is faster without ON gaps\nchart_Series(subset.SPY['2014-05-12/2014-05-16', 'Bid.Price'], name=sym_bol)\n\nsave(SPY, subset.SPY, file=\"SPY.RData\")\n\nload(file=\"SPY.RData\")  # big file\nload(file=\"SPY_daily.RData\")  # small file\n\n\n\n###########\n# analyze daily ts data\n\n\n# extract one day of ts data\ndaily_prices <- subset.SPY['2010-04-14', ]\ndaily_prices <- na.omit(daily_prices)  # omits too many bars?\n\n# calculate seconds mid bid-offer prices (evaluated at trade times)\n# mid_prices <- 0.5 * (daily_prices[, 'Bid.Price'] + daily_prices[, 'Ask.Price'])\n# mid_prices <- daily_prices['T13:00/T17:00', 'Trade.Price']\n# calculate seconds traded prices\n# mid_prices <- daily_prices[, c('Volume', 'Trade.Price')]\n# mid_prices <- daily_prices[, 'Trade.Price']\n# merge prices with volume data\n# vo_latume <- daily_prices['T13:00/T17:00', 'Volume']\n# vo_latume <- daily_prices[, 'Volume']\n# vo_latume[is.na(vo_latume)] <- 0\n# mid_prices <- cbind(mid_prices, vo_latume)\n# colnames(mid_prices) <- c('trade_price', 'volume')\n\n# get one day of data, after loading data into list:\ndaily_prices <- (daily_xts[[6]])['T09:30:00/T16:00:00', ]\n# calculate mid bid-offer prices\nmid_prices <- 0.5 * (daily_prices[, 'Bid.Price'] + daily_prices[, 'Ask.Price'])\nmid_prices <- na.omit(mid_prices)\ncolnames(mid_prices) <- \"Mid.Price\"\n\n\n### create test data\n\n# mid_prices <- xts(cumsum(rnorm(nrow(mid_prices))), order.by=index(daily_prices))\n# sine function with jumps\nmid_prices <- xts(sin(22*(1:nrow(daily_prices))/nrow(daily_prices)), order.by=index(daily_prices)) + 2\n# mid_prices <- sin(22*(1:dim(daily_prices)[1])/dim(daily_prices)[1])\n# prices_scrub <- mid_prices\ncolnames(mid_prices) <- \"Mid.Price\"\n\n# add noise\nmid_prices[c(1000,3000,5000,7000)] <- 1.1*mid_prices[c(1000,3000,5000,7000)]\nmid_prices[c(2000,4000,6000,8000)] <- 0.8*mid_prices[c(1000,3000,5000,7000)]\n# diff_prices <- xts(diff_prices, order.by=index(daily_xts[[6]])[10001:20000])\nplot(mid_prices)\n\n\n# median filter\ntest.blob <- xts(runmed(x=coredata(mid_prices), 11), order.by=index(mid_prices))\nplot(mid_prices, xlab=\"\", ylab=\"\", type='l')\nlines(test.blob, col='red', lwd=1)\n\n\n# calculate simple returns\ndiff_prices <- diff(mid_prices)\ndiff_prices[1, ] <- 0\ncolnames(diff_prices) <- \"diffs\"\ndiff_prices_fut <- lag(diff_prices, -1)\ndiff_prices_fut[nrow(diff_prices_fut)] <- 0\ncolnames(diff_prices_fut) <- \"diff_prices_fut\"\n\n# calculate log returns\n# daily_returns <- diff(log(mid_prices))/c(1, diff(.index(mid_prices)))\ndaily_returns <- diff(mid_prices)/c(1, diff(.index(mid_prices)))\ndaily_returns[1, ] <- 0\n\n\n### scrub data from single jump outliers, if two consecutive returns exceed threshold\n\n# calculate the (symmetric) running average absolute deviation\nagg_vol_window <- 51\n# abs_returns <- abs(as.vector(daily_returns))  # vector dispatches faster code\n# vo_lat <- runMean(abs_returns, n=agg_vol_window)\n# vo_lat[1:(agg_vol_window/2), ] <- vo_lat[(agg_vol_window/2+1), ]\n# system.time(vo_lat <- filter(abs_returns, filter=rep(1/agg_vol_window,agg_vol_window), sides=2))\n# daily_mean <- runmean(x=as.vector(daily_returns), k=agg_vol_window, alg=\"fast\", endrule=\"constant\", align=\"center\")\n# vo_lat <- runmean(x=abs(as.vector(daily_returns)-daily_mean), k=agg_vol_window, alg=\"fast\", endrule=\"constant\", align=\"center\")\n# vo_lat <- runmean(x=abs(as.vector(diff_prices)), k=agg_vol_window, alg=\"fast\", endrule=\"constant\", align=\"center\")\n# calculate vo_lat as running quantile\n# vo_lat <- runmad(x=as.vector(diff_prices), k=agg_vol_window, endrule=\"constant\", align=\"center\")\nvo_lat <- runquantile(x=abs(as.vector(diff_prices)), k=agg_vol_window, probs=0.9, endrule=\"constant\", align=\"center\")\nvo_lat <- xts(vo_lat, order.by=index(diff_prices))\ncolnames(vo_lat) <- \"volat\"\n# carry forward non-zero vo_lat values\nvo_lat[vo_lat==0] <- NA\nvo_lat <- na.locf(vo_lat)\nplot(vo_lat, xlab=\"\", ylab=\"\", type='l')\n\n\n# scrub the data\n# lag_daily_returns <- c(daily_returns[-1], tail(daily_returns, 1))\n# lag_daily_returns <- lag(daily_returns)\n# lag_daily_returns[1,] <- 0.0\n\n# find suspect values\nsuspect_threshold <- 1\n# suspect if sum of abs diffs greater than abs sum of diffs - doesn't work\n# sus_pect <- (abs(diff_prices) + abs(diff_prices_fut)) > suspect_threshold*abs(diff_prices+diff_prices_fut)\n# suspect if abs diffs greater than vo_lat, and if abs sum of diffs less than vo_lat\nsus_pect <- (\n  (abs(diff_prices) > suspect_threshold*vo_lat) & \n    (abs(diff_prices_fut) > suspect_threshold*vo_lat) & \n    (abs(diff_prices+diff_prices_fut) < 2*suspect_threshold*vo_lat)\n)\ncolnames(sus_pect) <- \"suspect\"\nsum(sus_pect)\nplot(sus_pect, xlab=\"\", ylab=\"\", type='l')\n\n\n# replace suspect values with NA\n# prices_scrub <- mid_prices\nprices_scrub <- mid_prices\nprices_scrub[sus_pect] <- NA\nprices_scrub <- na.locf(prices_scrub)\n\n# plot\nplot(prices_scrub, xlab=\"\", ylab=\"\", type='l')\nlines(prices_scrub, col='red', lwd=1)\n\n# calculate scrubbed returns\nreturns_scrub <- diff(prices_scrub)/c(1, diff(.index(prices_scrub)))\nreturns_scrub[1,] <- 0.0\n\n# mid_prices <- xts(raw.data[,2], order.by=as.POSIXlt(raw.data[,1]))\n\n# End scrub\n\n\n### plot scrub data\n\n# inspect scrubbing\ntest.blob <- cbind(mid_prices, diff_prices, diff_prices_fut, vo_lat, sus_pect, prices_scrub)\ncolnames(test.blob) <- c(\"mid_prices\", \"diff_prices\", \"diff_prices_fut\", \"vo_lat\", \"sus_pect\", \"prices_scrub\")\ntest.blob[995:1005]\nplot.zoo(test.blob[7990:8010])\n\n\n\n### data aggregation using to.period\n\nchartSeries(prices_scrub, theme=chartTheme(\"white\"))\n\n# bind prices_scrub with volume data and remove NA volumes with zeros\nprices_scrub <- cbind(prices_scrub, daily_prices[index(prices_scrub), \"Volume\"])\nprices_scrub[is.na(prices_scrub[, \"Volume\"]), \"Volume\"] <- 0\nhead(prices_scrub)\n\n# aggregate to OHLC minutes data and cumulative volume\nprices_scrub <- to.period(x=prices_scrub, period=\"minutes\")\nhead(prices_scrub)\nchartSeries(prices_scrub, theme=chartTheme(\"white\"))\n\n\n### data aggregation using custom code\n\n# calculate minutes traded prices\n# end_points <- endpoints(mid_prices, \"minutes\")\n# calculate traded prices every few bars\n# mid_prices <- daily_prices[(1:round(dim(daily_prices)[1]/10)), c('Volume', 'Trade.Price')]\n\n# calculate aggregation index\nagg_price_window <- 10  # number of periods per aggregation\nnum_agg <- trunc(dim(daily_prices)[1]/agg_price_window)  # number of aggregations\n# min end_points\n# end_points <- dim(daily_prices)[1] - (agg_price_window*(num_agg+1) - 1) + agg_price_window*(1:num_agg)\n# max end_points\n# end_points <- dim(daily_prices)[1] - agg_price_window*num_agg + agg_price_window*(1:num_agg)\n# range of end_points\nagg_range <- dim(daily_prices)[1] - (agg_price_window*(num_agg+1) - 1):(agg_price_window*num_agg)\n\n# calculate aggregated traded prices\n# mid_prices <- daily_prices[end_points, c('Volume', 'Trade.Price')]\n# colnames(mid_prices) <- c('trade_price', 'volume')\nmid_prices <- daily_prices[end_points, 'Trade.Price']\ncolnames(mid_prices) <- 'trade_price'\n\n# calculate aggregated returns given aggregation index start point\nagg_returns <- function(agg_start) {\n  mid_prices <- prices_scrub[(agg_start + agg_price_window*(1:num_agg)), ]\n  daily_returns <- diff(mid_prices)/c(1, diff(.index(mid_prices)))\n  daily_returns[1, ] <- 0\n  daily_agg_returns <<- rbind(daily_agg_returns, daily_returns)\n  agg_start\n  #  coredata(daily_returns)\n}  # end agg_returns\n\n\ndaily_agg_returns <- NULL\nagg_out <- sapply(agg_range, agg_returns)\ncolnames(daily_agg_returns) <- 'returns'\ndaily_agg_returns <- sqrt(agg_price_window)*daily_agg_returns\n\n\n# calculate stddev, skewness, and quantiles\nsd(x=coredata(daily_agg_returns))\nskewness(x=coredata(daily_agg_returns))\nquantile(x=daily_agg_returns, probs=c(0.05, 0.95))\nquantile(x=daily_agg_returns, probs=c(0.1, 0.9))\n\n\n# plot histograms of daily returns\nhist(daily_agg_returns, breaks=200, main=\"returns\", xlab=\"\", ylab=\"\", freq=FALSE)\nlines(density(daily_agg_returns), col='red', lwd=1)  # draw density\n\nhist(returns_scrub, breaks=200, main=\"returns\", xlab=\"\", ylab=\"\", freq=FALSE)\nlines(density(returns_scrub), col='red', lwd=1)  # draw density\n\nhist(returns_scrub, breaks=300, main=\"returns\", xlab=\"\", ylab=\"\", xlim=c(-0.05, 0.05), freq=FALSE)\nlines(density(returns_scrub), col='red', lwd=1)  # draw density\n\nhist(daily_returns, breaks=100, main=\"returns\", xlim=c(-2.0e-4, 2.0e-4), ylim=c(0, 10000), xlab=\"\", ylab=\"\", freq=FALSE)\nlines(density(daily_returns), col='red', lwd=1)  # draw density\n\n# title(main=ch.title, line=-1)  # add title\n\n\n# get hourly volumes\nend_points <- endpoints(mid_prices, \"hours\")\nperiod.apply(mid_prices[, 'volume'], INDEX=endpoints(mid_prices, \"hours\"), sum)\n\n\npnls <- period.apply(mid_prices[, 'volume'], INDEX=endpoints(mid_prices, \"minutes\"), sum)\n\n# get index of dates\n\n\n\n###########\n# load and scrub multiple days of data for a single symbol\nload_data <- function(sym_bol) {\n\n# create path to directory with *.RData files\n  file_dir <- file.path(data_dir, sym_bol)\n# get list of *.RData files\n  file_list <- list.files(file_dir)\n# create paths to *.RData files\n  file_names <- file.path(file_dir, file_list)\n\n# load data into list\n  data <- sapply(file_names, function(file_name) {\n    cat(\"loading\", sym_bol, \"frome file: \", file_name, \"\\n\")\n    data_name <- load(file_name)\n    get(data_name)\n  })\n\n# scrub and aggregate the data\n  data <- sapply(data, scrub_agg)\n\n# recursively \"rbind\" the list into a single xts\n  data <- do_call_rbind(data)\n\n  colnames(data) <- sapply(strsplit(colnames(data), split=\"[.]\"), \n                           function(strng) paste(sym_bol, strng[-1], sep=\".\"))\n\n  assign(sym_bol, data)\n\n  save(list=eval(sym_bol), file=paste0(sym_bol, \".RData\"))\n\n}  # end load_data\n\n# load list of symbols\nsym_bols <- read.csv(file=\"etf_list_hf.csv\")\nsym_bols <- sym_bols[[1]]\n\n# load data for a single symbol\nload_data(\"IWF\")\n# load data for list of symbols\nsapply(head(sym_bols), load_data)\n\n\n\n\n### extra legacy code\n\n# load second data for single day - works\nload(\"E:/mktdata/sec/ESM9/2009.04.02.ESM9.rdata\")\ndim(ESM9)\nlen_es <- dim(ESM9)[1]\n# inspect\nESM9[(len_es-10010):(len_es-10000), ]\n# plot\nplot(ESM9[((len_es-20000):(len_es-10000)), \"Bid.Price\"])\n\n\n# tics data works\ngetSymbols(\"ZSK5\")\n\n# doesn't work\ngetSymbols(\"MSFT\", verbose=FALSE, dir=data_dir, src=\"rda\")\nfile  MSFT.rda  does not exist  in  E:/mktdata/ ....skipping\n[1] \"MSFT\"\n\n# doesn't work\ngetSymbols(\"ESH3\")\nNULL\nWarning message:\n  In getSymbols.FI(Symbols=\"ESH3\", env=<environment>, verbose=FALSE,  :\n                    No data found.\n\n# doesn't work\ngetSymbols(\"ZQZ9\")\nError in FUN(1L[[1L]], ...) : \n  must define instrument first to call with 'use_identifier'\nIn addition: Warning message:\n  In getInstrument(Symbols[[i]], silent=FALSE) :\n  instrument ZQZ9 not found, please create it first.\n> getSymbols(\"QZ9\")\n\n# doesn't work\ngetSymbols(\"ZSK7\")\nNULL\nWarning message:\n  In getSymbols.FI(Symbols=\"ZSK7\", env=<environment>, verbose=FALSE,  :\n                    No data found.\n\n###\n\n# get data from multiple .Rdata files\ngetSymbols.FI <- function (symbols_list, date_from=\"2010-01-01\", to=Sys.Date(), ..., \n          dir=\"\", return_class=\"xts\", extension=\"rda\", split_method=c(\"days\", \"common\"), \n          use_identifier=NA, date_format=NULL, verbose=TRUE, \n          days_to_omit=c(\"Saturday\", \"Sunday\"), indexTZ=NA) {\n\n# looks redundant\n  if (is.null(date_format)) \n    date_format <- \"%Y.%m.%d\"\n# what's this?\n  if (is.null(days_to_omit)) \n    days_to_omit <- \"NULL\"\n\n# copy named dots arguments into function environment - not sure why this is needed\n  this_env <- environment()\n  for (var in names(list(...))) {\n    assign(var, list(...)[[var]], this_env)\n  }\n\n# recursive \"rbind\" function for list arguments - same as do.call.rbind\n  do_call_rbind <- function(list_var) {\n# call lapply in a loop to divide list_var by half, binding neighboring elements\n    while (length(list_var) > 1) {\n# index of odd list elements\n      odd_index <- seq(from=1, to=length(list_var), by=2)\n# bind neighboring elements and divide list_var by half\n      list_var <- lapply(odd_index, function(in_dex) {\n        if (in_dex==length(list_var)) {\n          return(list_var[[in_dex]])\n        }\n        return(rbind(list_var[[in_dex]], list_var[[in_dex+1]]))\n      })  # end lapply\n    }  # end while\n# list_var has only one element - return it\n  list_var[[1]]\n  }  # end do_call_rbind\n\n# assign input argument values to hidden '.*' variables\n# the variables hasArg.* are used in pickArg()\nif (hasArg.date_from <- hasArg(date_from)) \n    .date_from <- date_from\n  if (hasArg.to <- hasArg(to)) \n    .to <- to\n  if (hasArg.dir <- hasArg(dir)) \n    .dir <- dir\n  if (hasArg.return_class <- hasArg(return_class)) \n    .return_class <- return_class\n  if (hasArg.extension <- hasArg(extension)) \n    .extension <- extension\n  if (hasArg.split_method <- hasArg(split_method)) \n    .split_method <- split_method\n  if (hasArg.use_identifier <- hasArg(use_identifier)) \n    .use_identifier <- use_identifier\n  if (hasArg.date_format <- hasArg(date_format)) \n    .date_format <- date_format\n  if (hasArg.verbose <- hasArg(verbose)) \n    .verbose <- verbose\n  if (hasArg.days_to_omit <- hasArg(days_to_omit)) \n    .days_to_omit <- days_to_omit\n  if (hasArg.indexTZ <- hasArg(indexTZ)) \n    .indexTZ <- indexTZ\n\n  importDefaults(\"getSymbols.FI\")\n\n# assign default.* values to those passed through argument list of getSymbols.FI\n# the default.* variables are used in pickArg()\n# the default.* and '.*' variables are duplicates of the same arguments\n  default.date_from <- date_from\n  default.to <- to\n  default.dir <- dir\n  default.return_class <- return_class\n  default.extension <- extension\n  default.split_method <- split_method[1]\n  default.use_identifier <- use_identifier\n  default.date_format <- date_format\n  default.verbose <- verbose\n  default.days_to_omit <- days_to_omit\n  default.indexTZ <- indexTZ\n# end unused variables\n\n  auto.assign <- if (hasArg(auto.assign)) {\n    auto.assign\n  } else {\n    TRUE\n  }\n\n  env <- if (hasArg(env)) {\n    env\n  }\n  else .GlobalEnv\n\n# get default load parameters for all Symbols\n  symbol_lookup <- getSymbolLookup()\n\n# get default load parameters for symbol\n  pickArg <- function(x, symbol_name) {\n# check if symbol_name was passed as argument, and get '.*' value\n    if (get(paste(\"hasArg\", x, sep=\".\"))) {\n      get(paste(\".\", x, sep=\"\"))\n    }\n# get value that was set using setSymbolLookup\n    else if (!is.null(symbol_lookup[[symbol_name]][[x]])) {\n      symbol_lookup[[symbol_name]][[x]]\n    }\n# get 'default.*' value\n    else get(paste(\"default\", x, sep=\".\"))\n  }  # end pickArg\n\n  fr <- NULL  # \"fr\" is never used\n\n### huge lapply over list of symbols\n  datl <- lapply(1:length(symbols_list),  # load data for list of symbols\n                  function(symbol_index) {  # load data for single symbol\n                    symbol_i <- symbols_list[[symbol_index]]\n\n# get default load parameters for symbol_i\n                  from <- pickArg(\"from\", symbol_i)\n                  to <- pickArg(\"to\", symbol_i)\n                  dir <- pickArg(\"dir\", symbol_i)\n                  return_class <- pickArg(\"return_class\", symbol_i)\n                  file_extension <- pickArg(\"extension\", symbol_i)\n                  split_method <- pickArg(\"split_method\", symbol_i)\n                  use_identifier <- pickArg(\"use_identifier\", symbol_i)\n                  date_format <- pickArg(\"date_format\", symbol_i)\n                  verbose <- pickArg(\"verbose\", symbol_i)\n                  days_to_omit <- pickArg(\"days_to_omit\", symbol_i)\n                  indexTZ <- pickArg(\"indexTZ\", symbol_i)\n\n# if use_identifier is set, then extract identifier from symbol\n                  instr_str <- NA\n                  if (!is.na(use_identifier)) {\n                    tmp_instr <- try(getInstrument(symbol_i, silent=FALSE))\n                    if (inherits(tmp_instr, \"try-error\") || !is.instrument(tmp_instr)) \n                        stop(\"must define instrument first to call with 'use_identifier'\")\n                    if (!use_identifier==\"primary_id\") {\n                        instr_str <- make.names(tmp_instr$identifiers[[use_identifier]])\n                    }\n                    else instr_str <- make.names(tmp_instr[[use_identifier]])\n                    if (length(instr_str)==0L) \n                        stop(\"Could not find instrument. Try with use_identifier=NA\")\n                  }  # end if\n\n# assign symbol name from either identifier or symbol\n                  symbol_name <- ifelse(is.na(instr_str), make.names(symbol_i), instr_str)\n\n# drop last \"/\" from dir\n                  ndc <- nchar(dir)\n                  if (substr(dir, ndc, ndc)==\"/\")\n                    dir <- substr(dir, 1, ndc - 1)\n# add symbol_name to dir\n                  ssd <- strsplit(dir, \"/\")[[1]]\n                  if (identical(character(0), ssd) || \n                         (!identical(character(0), ssd) && ssd[length(ssd)] != symbol_name))\n                    dir <- paste(dir, symbol_name, sep=\"/\")\n\n# load data for single symbol from its directory\n                  if (!dir==\"\" && !file.exists(dir)) {\n                    if (verbose)\n                       cat(\"\\ndirectory \", dir, \" does not exist, skipping\\n\")\n                  } else {\n                    if (verbose)\n                       cat(\"loading \", symbol_i, \".....\\n\")\n\n### start switch - either \"days\" or \"common\" \n                    switch(split_method[1],\n                      days={  # load from daily files\n# create vector of dates and file names\n                            StartDate <- as.Date(from)\n                            EndDate <- as.Date(to)\n                            vec_dates <- as.Date(StartDate:EndDate)\n                            vec_dates <- vec_dates[!weekdays(vec_dates) %in% days_to_omit]\n                            vec_dates <- format(vec_dates, format=date_format)\n                            vec_file_names <- paste(vec_dates, symbol_name, file_extension, sep=\".\")\n                            if (dir!=\"\") vec_file_names <- file.path(dir, vec_file_names)\n\n# loop over file names and load data\n                            data_list <- lapply(vec_file_names, function(file_name_full) {\n                              file_name <- strsplit(file_name_full, \"/\")[[1]]\n                              file_name <- file_name[length(file_name)]\n                              if (verbose) cat(\"Reading \", file_name, \"...\")\n                              if (!file.exists(file_name_full)) {\n                                if (verbose) cat(\" failed. File not found in \", dir, \" ... skipping\\n\")\n                              } else {\n                                data_name <- load(file_name_full)  # load invisibly and get character string of object names\n                                data_object <- get(data_name)  # get value of named object\n                                if (!is.na(indexTZ) && !is.null(data_object)) indexTZ(data_object) <- indexTZ\n                                if (verbose) cat(\" done.\\n\")\n                                data_object  # return data from loop\n                              }  # end if\n                            }  # end anon function\n                            )  # end lapply\n\n                            if (verbose) cat(\"rbinding data ... \")\n                            data_complete <- do_call_rbind(data_list)\n                            },  # end days\n\n                            common={\n                              file_name <- paste(symbol_name, file_extension, sep=\".\")\n                              if (dir != \"\") file_name <- file.path(dir, file_name)\n                              if (!file.exists(file_name)) {\n                                if (verbose) cat(\"file \", paste(symbol_name, file_extension, sep=\".\"), \" does not exist in \", dir, \"....skipping\\n\")\n                              } else {\n                                data_name <- load(file_name)\n                                data_object <- get(data_name)\n                                if (!is.na(indexTZ) && !is.null(data_object)) indexTZ(data_object) <- indexTZ\n                                assign(\"data_complete\", data_object)\n                                if (verbose) cat(\"done.\\n\")\n                              }\n                            }  # end common\n\n                        )  # end switch\n\n                        data_complete <- quantmod:::convert.time.series(data_complete=data_complete, return_class=return_class)\n                        symbol_i <- make.names(symbol_i)\n                        data_out <- list()\n                        data_out[[symbol_i]] <- data_complete\n                        if (verbose) \n                           cat(\"done.\\n\")\n                        data_out\n                       }  # end load data for single symbol\n                 }  # end anon function for loading single symbol\n\n  )  # end lapply over list of symbols\n\n\n  if (length(Filter(\"+\", lapply(datl, length)))==0) {\n    warning(\"No data found.\")\n    return(NULL)\n  }\n\n  datl.names <- do.call(c, lapply(datl, names))\n  missing <- symbols_list[!symbols_list %in% datl.names]\n  if (length(missing) > 0) \n    warning(\"No data found for \", paste(missing, collapse=\" \"))\n  if (auto.assign) {\n    out <- Filter(function(x) length(x) > 0, datl)\n    invisible(lapply(out, function(x) assign(names(x), x[[1]], pos=env)))\n    return(datl.names)\n  }\n  else {\n    out <- lapply(datl, function(x) {\n      if (length(x) > 0) \n        x[[1]]\n    })\n    if (length(out)==1) \n      return(out[[1]])\n    else {\n      names(out) <- symbols_list\n      return(out)\n    }\n  }\n}\n\n<environment: namespace:FinancialInstrument>\n\n\n",
    "created" : 1423677935434.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2473772335",
    "id" : "FCC838EF",
    "lastKnownWriteTime" : 1423871216,
    "path" : "C:/Develop/R/scripts/hfreq_aggregation.R",
    "project_path" : null,
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}