{
  "name": "Highfreq",
  "tagline": "R package for high frequency time series data management",
  "body": "---\r\ntitle: HighFreq Package for High Frequency Time Series Data Management\r\nauthor: Jerzy Pawlowski (algoquant)\r\nabstract: Functions for chaining and joining time series, scrubbing bad data, managing time zones and alligning time indices, converting TAQ data to OHLC format, aggregating data to lower frequency, estimating volatility, skew, and higher moments.\r\ntags: high frequency, time series, volatility\r\n---\r\n\r\n[![Build Status](https://travis-ci.org/algoquant/HighFreq.svg?branch=master)](https://travis-ci.org/algoquant/HighFreq)\r\n\r\n\r\n### Overview\r\n\r\nThe motivation for the *HighFreq* package is to create a library of functions designed for managing trade and quote (*TAQ*) and *OHLC* data, and for efficiently estimating various statistics, like volatility, skew, Hurst exponent, and Sharpe ratio, from that data.  \r\n\r\nThe are several other packages which offer much of this functionality, like for example:\r\n\r\n+ package [xts](https://cran.r-project.org/web/packages/xts/index.html)  \r\n\r\n+ package [TTR](https://cran.r-project.org/web/packages/TTR/index.html)  \r\n\r\n+ package [PerformanceAnalytics](https://cran.r-project.org/web/packages/PerformanceAnalytics/index.html)  \r\n\r\n+ package [highfrequency](https://cran.r-project.org/web/packages/highfrequency/index.html)  \r\n\r\nUnfortunately many of the functions in these packages are either too slow, or lack some critical functionality, or produce data in inconsistent formats (with *NA* values, etc.)  The *HighFreq* package aims to create a unified framework, with consistent data formats and naming conventions. \r\n\r\nThe *HighFreq* package relies on *OHLC* price and volume data formatted as *xts* time series, because the *OHLC* data format provides an efficient way of compressing *TAQ* data, while preserving information about price levels, volatility (range), and trading volumes.  Most existing packages don't rely on *OHLC* data, so their statistical estimators are much less efficient than those in package *HighFreq*. \r\n\r\n\r\n### Running and Rolling Statistics Over Time Series Data\r\n\r\nDefinitions of running and rolling statistics (aggregations):\r\n\r\n+ A statistic is some function of *OHLC* data, for example the difference between\r\n*high* minus *low* prices is a simple statistic.  Estimators of volatility, skew, and higher moments are also statistics.\r\n\r\n+ So-called running statistics are based on individual bars of *OHLC* data, while rolling statistics are based on multiple bars of *OHLC* data taken from a lookback window.\r\nRolling statistics can be calculated from running statistics by calculating weighted averages.\r\n\r\n+ The functions called *run_\\** estimate running statistics based on each bar of *OHLC* data, and produce a single-column *xts* time series with the same number of rows as the *OHLC* time series.\r\n\r\n+ The functions called *roll_\\** estimate rolling statistics based on multiple bars of *OHLC* data taken from a lookback window, and often produce a single-column *xts* time series with the same number of rows as the *OHLC* time series.\r\n\r\n+ Running and rolling statistics also represent a form of data aggregations, and can include many standard technical indicators, like *VWAP*, *Bollinger Bands*, etc.\r\n\r\n<br>\r\n\r\n\r\n### Functions for data scrubbing, formatting, and aggregation\r\n\r\nThe *HighFreq* package contains several categories of functions designed for:\r\n\r\n+ managing *TAQ* and *OHLC* time series, \r\n\r\n+ estimating running and rolling statistics over time series, \r\n\r\n\r\nThe *HighFreq* package contains functions for:\r\n\r\n+ chaining and joining time series, \r\n\r\n+ scrubbing bad data from time series, \r\n\r\n+ managing time zones and alligning time indices, \r\n\r\n+ converting *TAQ* data to *OHLC* format, \r\n\r\n+ aggregating data to lower frequency (periodicity), \r\n\r\n+ estimating running statistics from *OHLC* data, such as volatility, skew, and higher moments (functions called *run_\\**), \r\n\r\n+ calculating rolling aggregations (VWAP, Hurst exponent, Sharpe ratio, etc.), \r\n\r\n+ calculating seasonality aggregations, \r\n\r\n+ creating random *TAQ* and *OHLC* time series, \r\n\r\n\r\n### Installation and loading\r\n\r\nInstall package *HighFreq* from github:  \r\n\r\n```r\r\ninstall.packages(\"devtools\")\r\ndevtools::install_github(repo=\"algoquant/HighFreq\")\r\nlibrary(HighFreq)\r\n```\r\n<br>\r\n\r\nInstall package *HighFreq* from source on local drive:  \r\n\r\n```r\r\ninstall.packages(pkgs=\"C:/Develop/R/HighFreq\", repos=NULL, type=\"source\")\r\n# Install package from source on local drive using R CMD\r\nR CMD INSTALL C:\\Develop\\R\\HighFreq\r\nlibrary(HighFreq)\r\n```\r\n<br>\r\n\r\nBuild reference manual for package *HighFreq* from *.Rd* files:  \r\n\r\n```r\r\nsystem(\"R CMD Rd2pdf C:/Develop/R/HighFreq\")\r\nR CMD Rd2pdf C:\\Develop\\R\\HighFreq\r\n```\r\n<br>\r\n\r\n\r\n### Data\r\n\r\nThe *HighFreq* package includes three *xts* time series called *SPY*, *TLT*, and *VXX*, containing intraday 1-minute *OHLC* data for the *SPY*, *TLT*, and *VXX* ETFs.  The *HighFreq* package also includes an *xts* time series called *SPY_TAQ* with a single day of *TAQ* data for the *SPY*ETF.  The data is set up for lazy loading, so it doesn't require calling `data(hf_data)` to load it before being able to call it.\r\n\r\nThe data source is the \r\n[Wharton Research Data Service](https://wrds-web.wharton.upenn.edu/wrds/)  \r\n\r\n\r\n### Examples\r\n\r\nAggregate *TAQ* data into a 1-minute bar *OHLC* time series:  \r\n\r\n```r\r\n# aggregate TAQ data to 1-min OHLC bar data, for a single symbol, and save to file\r\nsym_bol <- \"SPY\"\r\nsave_scrub_agg(sym_bol, \r\n               data_dir=\"E:/mktdata/sec/\", \r\n               output_dir=\"E:/output/data/\")\r\n```\r\n<br>\r\n\r\nCalculate daily trading volume:  \r\n\r\n```r\r\ndaily_volume <- apply.daily(x=Vo(SPY), FUN=sum)\r\ncolnames(daily_volume) <- paste0(na_me(SPY), \".Volume\")\r\nchart_Series(x=daily_volume, name=\"daily trading volumes for SPY\")\r\n```\r\n<br>\r\n\r\nCalculate daily volume-weighted variance (volatility):  \r\n\r\n```r\r\ndaily_var <- apply.daily(x=SPY, FUN=agg_regate, mo_ment=\"run_variance\")\r\ncolnames(daily_var) <- paste0(na_me(SPY), \".Var\")\r\nchart_Series(x=daily_var, name=\"daily variance for SPY\")\r\n```\r\n<br>\r\n\r\nCalculate daily skew:  \r\n\r\n```r\r\ndaily_skew <- apply.daily(x=SPY, FUN=agg_regate, mo_ment=\"run_skew\")\r\ndaily_skew <- daily_skew/(daily_var)^(1.5)\r\ncolnames(daily_skew) <- paste0(na_me(SPY), \".Skew\")\r\nchart_Series(x=daily_skew, name=\"daily skew for SPY\")\r\n```\r\n<br>\r\n\r\nCalculate rolling prices:  \r\n\r\n```r\r\nroll_prices <- rutils::roll_sum(Op(SPY), win_dow=10)/10\r\ncolnames(roll_prices) <- paste0(\"SPY\", \".Rets\")\r\n# plot candle chart\r\nchart_Series(SPY[\"2013-11-12\", ], name=paste(\"SPY\", \"Prices\"))\r\nadd_TA(roll_prices[\"2013-11-12\"], on=1, col=\"red\", lwd=2)\r\n```\r\n<br>\r\n\r\nCalculate rolling volume-weighted variance:  \r\n\r\n```r\r\nroll_var <- roll_moment(oh_lc=SPY[\"2012\"], mo_ment=\"run_variance\", win_dow = 10)\r\n# plot without overnight jump\r\nchart_Series(roll_var[\"2012-11-12\", ][-(1:11)], name=paste(\"SPY\", \"rolling volume-weighted variance\"))\r\n```\r\n<br>\r\n\r\nCalculate daily seasonality of variance:  \r\n\r\n```r\r\nvar_seasonal <- season_ality(run_variance(oh_lc=SPY))\r\ncolnames(var_seasonal) <- \"SPY.var_seasonal\"\r\nchart_Series(x=var_seasonal, name=\"SPY variance daily seasonality\")\r\n```\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}